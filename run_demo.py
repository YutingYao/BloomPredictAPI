#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è“è—»é¢„æµ‹APIæ¼”ç¤ºè„šæœ¬ - æ¨¡æ‹ŸAPIåŠŸèƒ½å±•ç¤º
"""

import json
import time
from datetime import datetime
from typing import Dict, List, Any

class MockPredictionAPI:
    """æ¨¡æ‹Ÿè“è—»é¢„æµ‹APIç±»"""
    
    def __init__(self):
        self.stations = [
            {"name": "èƒ¥æ¹–å¿ƒ", "name_en": "Xuhu Center", "zone": "é‡æ±¡æŸ“ä¸é«˜é£é™©åŒº"},
            {"name": "é”¡ä¸œæ°´å‚", "name_en": "Xidong Water Plant", "zone": "é‡æ±¡æŸ“ä¸é«˜é£é™©åŒº"},
            {"name": "å¹³å°å±±", "name_en": "Pingtai Mountain", "zone": "èƒŒæ™¯ä¸å‚ç…§åŒº"},
            {"name": "tuoshan", "name_en": "Tuoshan Mountain", "zone": "èƒŒæ™¯ä¸å‚ç…§åŒº"},
            {"name": "lanshanzui", "name_en": "Lanshan Cape", "zone": "è¾¹ç•Œæ¡ä»¶åŒº"},
            {"name": "äº”é‡Œæ¹–å¿ƒ", "name_en": "Wulihu Center", "zone": "è¾¹ç•Œæ¡ä»¶åŒº"}
        ]
        
        self.models = {
            "lstm": {"name": "LSTM", "improvement": 0.0},
            "grud": {"name": "GRU-D", "improvement": 50.07},
            "tcn": {"name": "TCN", "improvement": -1.88},
            "xgboost": {"name": "XGBoost", "improvement": 16.43}
        }
        
        # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®
        self.performance_data = {
            "èƒ¥æ¹–å¿ƒ": {"grud": 77.41, "tcn": -0.84, "xgboost": 17.90},
            "é”¡ä¸œæ°´å‚": {"grud": 55.13, "tcn": 1.56, "xgboost": -37.59},
            "å¹³å°å±±": {"grud": 16.32, "tcn": -20.09, "xgboost": 100.0},
            "tuoshan": {"grud": 79.78, "tcn": 0.07, "xgboost": 49.31},
            "lanshanzui": {"grud": 28.83, "tcn": 5.35, "xgboost": 9.32},
            "äº”é‡Œæ¹–å¿ƒ": {"grud": 42.93, "tcn": 2.69, "xgboost": -40.37}
        }
    
    def predict(self, station: str, model_type: str, predict_days: int, input_data: Dict) -> Dict:
        """æ¨¡æ‹Ÿé¢„æµ‹åŠŸèƒ½"""
        print(f"ğŸ”® æ­£åœ¨ä½¿ç”¨{model_type.upper()}æ¨¡å‹é¢„æµ‹{station}ç«™ç‚¹æœªæ¥{predict_days}å¤©çš„è“è—»å¯†åº¦...")
        time.sleep(1)  # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
        
        # ç”Ÿæˆæ¨¡æ‹Ÿé¢„æµ‹ç»“æœ
        import random
        random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡ç°
        
        base_value = 0.1
        predictions = []
        for i in range(predict_days):
            # æ¨¡æ‹Ÿå¢é•¿ç‡å˜åŒ–
            variation = random.uniform(-0.05, 0.1)
            value = base_value + variation + i * 0.02
            predictions.append(round(value, 4))
        
        # è®¡ç®—ç½®ä¿¡åº¦
        improvement = self.performance_data.get(station, {}).get(model_type, 0)
        confidence = min(0.95, max(0.3, (improvement + 50) / 150))
        
        return {
            "success": True,
            "data": {
                "station": station,
                "model_type": model_type,
                "predict_days": predict_days,
                "prediction": predictions,
                "confidence": round(confidence, 3),
                "rmse": round(random.uniform(0.1, 2.0), 4),
                "model_info": {
                    "name": self.models[model_type]["name"],
                    "improvement_over_lstm": f"{improvement:.2f}%"
                }
            },
            "message": "é¢„æµ‹æˆåŠŸ",
            "timestamp": datetime.now().isoformat()
        }
    
    def get_performance(self, station: str = None) -> Dict:
        """è·å–æ¨¡å‹æ€§èƒ½å¯¹æ¯”"""
        print(f"ğŸ“Š è·å–{'å…¨éƒ¨ç«™ç‚¹' if not station else station}çš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”æ•°æ®...")
        time.sleep(0.5)
        
        target_stations = [station] if station else [s["name"] for s in self.stations]
        
        performance_list = []
        for station_name in target_stations:
            if station_name in self.performance_data:
                station_info = next(s for s in self.stations if s["name"] == station_name)
                models_perf = []
                
                for model_type, improvement in self.performance_data[station_name].items():
                    models_perf.append({
                        "model_type": model_type,
                        "model_name": self.models[model_type]["name"],
                        "improvement_over_lstm": improvement,
                        "status": "ä¼˜ç§€" if improvement > 30 else "è‰¯å¥½" if improvement > 0 else "ä¸€èˆ¬"
                    })
                
                performance_list.append({
                    "station": station_name,
                    "zone": station_info["zone"],
                    "models": models_perf
                })
        
        return {
            "success": True,
            "data": {
                "station_performance": performance_list,
                "summary": {
                    "best_model": "grud",
                    "overall_improvement": 33.6,
                    "recommended_model": "grud"
                }
            },
            "message": "æ€§èƒ½æ•°æ®è·å–æˆåŠŸ"
        }

def demo_prediction():
    """æ¼”ç¤ºé¢„æµ‹åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸŒŠ è“è—»é¢„æµ‹ç³»ç»ŸAPIæ¼”ç¤º")
    print("=" * 60)
    
    api = MockPredictionAPI()
    
    # å±•ç¤ºæ”¯æŒçš„ç«™ç‚¹
    print("\nğŸ“ æ”¯æŒçš„ç›‘æµ‹ç«™ç‚¹:")
    for i, station in enumerate(api.stations, 1):
        print(f"  {i}. {station['name']} ({station['name_en']}) - {station['zone']}")
    
    # å±•ç¤ºæ”¯æŒçš„æ¨¡å‹
    print("\nğŸ¤– æ”¯æŒçš„é¢„æµ‹æ¨¡å‹:")
    for model_type, info in api.models.items():
        recommended = " â­" if model_type == "grud" else ""
        print(f"  - {info['name']} ({model_type.upper()}): å¹³å‡æ”¹å–„ç‡ {info['improvement']:.2f}%{recommended}")
    
    print("\n" + "=" * 60)
    print("ğŸ§ª é¢„æµ‹æ¼”ç¤º")
    print("=" * 60)
    
    # æ¼”ç¤ºé¢„æµ‹
    test_cases = [
        {"station": "èƒ¥æ¹–å¿ƒ", "model": "grud", "days": 7},
        {"station": "å¹³å°å±±", "model": "xgboost", "days": 3},
        {"station": "tuoshan", "model": "grud", "days": 14}
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ”¬ æµ‹è¯•æ¡ˆä¾‹ {i}: {case['station']} - {case['model'].upper()}æ¨¡å‹ - {case['days']}å¤©é¢„æµ‹")
        
        # æ¨¡æ‹Ÿè¾“å…¥æ•°æ®
        input_data = {
            "temperature": 25.5,
            "oxygen": 8.2,
            "TN": 1.5,
            "TP": 0.08,
            "pH": 7.8,
            "turbidity": 15.2
        }
        
        print("  è¾“å…¥æ•°æ®:")
        for key, value in input_data.items():
            print(f"    {key}: {value}")
        
        # æ‰§è¡Œé¢„æµ‹
        result = api.predict(case["station"], case["model"], case["days"], input_data)
        
        if result["success"]:
            data = result["data"]
            print(f"  âœ… é¢„æµ‹æˆåŠŸ!")
            print(f"    ç½®ä¿¡åº¦: {data['confidence']:.1%}")
            print(f"    æ¨¡å‹æ”¹å–„ç‡: {data['model_info']['improvement_over_lstm']}")
            predictions = data['prediction']
            print(f"    é¢„æµ‹ç»“æœ: {predictions[:3]}{'...' if len(predictions) > 3 else ''}")
        else:
            print(f"  âŒ é¢„æµ‹å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")

def demo_performance():
    """æ¼”ç¤ºæ€§èƒ½å¯¹æ¯”åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯¹æ¯”æ¼”ç¤º")
    print("=" * 60)
    
    api = MockPredictionAPI()
    
    # è·å–æ€§èƒ½æ•°æ®
    result = api.get_performance()
    
    if result["success"]:
        data = result["data"]
        print("\nğŸ† å„ç«™ç‚¹æœ€ä½³æ¨¡å‹è¡¨ç°:")
        
        for station_perf in data["station_performance"]:
            station = station_perf["station"]
            zone = station_perf["zone"]
            models = station_perf["models"]
            
            # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
            best_model = max(models, key=lambda x: x["improvement_over_lstm"])
            
            print(f"\n  ğŸ“ {station} ({zone}):")
            print(f"    ğŸ¥‡ æœ€ä½³æ¨¡å‹: {best_model['model_name']} (æ”¹å–„ç‡: {best_model['improvement_over_lstm']:.2f}%)")
            
            # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹è¡¨ç°
            for model in sorted(models, key=lambda x: x["improvement_over_lstm"], reverse=True):
                status_icon = "ğŸŸ¢" if model["status"] == "ä¼˜ç§€" else "ğŸŸ¡" if model["status"] == "è‰¯å¥½" else "ğŸ”´"
                print(f"      {status_icon} {model['model_name']}: {model['improvement_over_lstm']:+.2f}%")
        
        # æ˜¾ç¤ºæ€»ç»“
        summary = data["summary"]
        print(f"\nğŸ¯ æ€»ä½“åˆ†æ:")
        print(f"  â€¢ æ¨èæ¨¡å‹: {summary['recommended_model'].upper()}")
        print(f"  â€¢ å¹³å‡æ”¹å–„ç‡: {summary['overall_improvement']:.2f}%")
        print(f"  â€¢ æœ€ä½³æ¨¡å‹: {summary['best_model'].upper()}")

def demo_api_endpoints():
    """æ¼”ç¤ºAPIæ¥å£"""
    print("\n" + "=" * 60)
    print("ğŸ”— APIæ¥å£æ¼”ç¤º")
    print("=" * 60)
    
    base_url = "http://localhost:8000"
    
    endpoints = [
        {
            "method": "GET",
            "path": "/health",
            "description": "å¥åº·æ£€æŸ¥",
            "example": f"curl {base_url}/health"
        },
        {
            "method": "GET", 
            "path": "/api/stations",
            "description": "è·å–æ”¯æŒçš„ç›‘æµ‹ç«™ç‚¹",
            "example": f"curl {base_url}/api/stations"
        },
        {
            "method": "GET",
            "path": "/api/models", 
            "description": "è·å–æ”¯æŒçš„é¢„æµ‹æ¨¡å‹",
            "example": f"curl {base_url}/api/models"
        },
        {
            "method": "POST",
            "path": "/api/predict",
            "description": "è“è—»å¯†åº¦é¢„æµ‹",
            "example": f"""curl -X POST {base_url}/api/predict \\
  -H "Content-Type: application/json" \\
  -d '{{"station": "èƒ¥æ¹–å¿ƒ", "model_type": "grud", "predict_days": 7, "input_data": {{"temperature": 25.5, "oxygen": 8.2, "TN": 1.5, "TP": 0.08}}}}'"""
        },
        {
            "method": "POST",
            "path": "/api/model-performance",
            "description": "æ¨¡å‹æ€§èƒ½å¯¹æ¯”",
            "example": f"""curl -X POST {base_url}/api/model-performance \\
  -H "Content-Type: application/json" \\
  -d '{{"station": "èƒ¥æ¹–å¿ƒ", "model_types": ["lstm", "grud"]}}'"""
        }
    ]
    
    print("\nğŸ“‹ å¯ç”¨çš„APIæ¥å£:")
    for endpoint in endpoints:
        print(f"\n  ğŸ”¸ {endpoint['method']} {endpoint['path']}")
        print(f"    æè¿°: {endpoint['description']}")
        print(f"    ç¤ºä¾‹: {endpoint['example'][:80]}{'...' if len(endpoint['example']) > 80 else ''}")
    
    print(f"\nğŸ“š å®Œæ•´APIæ–‡æ¡£: {base_url}/docs")
    print(f"ğŸ” Redocæ–‡æ¡£: {base_url}/redoc")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    try:
        # é¢„æµ‹åŠŸèƒ½æ¼”ç¤º
        demo_prediction()
        
        # æ€§èƒ½å¯¹æ¯”æ¼”ç¤º
        demo_performance()
        
        # APIæ¥å£æ¼”ç¤º
        demo_api_endpoints()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆ!")
        print("=" * 60)
        print("\nè¦å¯åŠ¨çœŸå®çš„APIæœåŠ¡å™¨ï¼Œè¯·è¿è¡Œ:")
        print("  python start_server.py")
        print("\næˆ–è€…:")
        print("  python main.py")
        print("\nç„¶åè®¿é—® http://localhost:8000/docs æŸ¥çœ‹å®Œæ•´APIæ–‡æ¡£")
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ¼”ç¤ºå·²åœæ­¢")

if __name__ == "__main__":
    main()
